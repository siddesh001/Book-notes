<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
                              "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd" >
<html xmlns="http://www.w3.org/TR/1999/REC-html-in-xml" xml:lang="en"
	lang="en">
	<head>
                <meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8" />
                <!-- HTML5 -->
                <meta charset="UTF-8"/>
		<style type="text/css">
                    .bodyContainer {
    font-family: Arial, Helvetica, sans-serif;
    text-align: center;
    padding-left: 32px;
    padding-right: 32px;
}

.notebookFor {
    font-size: 18px;
    font-weight: 700;
    text-align: center;
    color: rgb(119, 119, 119);
    margin: 24px 0px 0px;
    padding: 0px;
}

.bookTitle {
    font-size: 32px;
    font-weight: 700;
    text-align: center;
    color: #333333;
    margin-top: 22px;
    padding: 0px;
}

.authors {
    font-size: 13px;
    font-weight: 700;
    text-align: center;
    color: rgb(119, 119, 119);
    margin-top: 22px;
    margin-bottom: 24px; 
    padding: 0px;
}

.citation {
    font-size: 16px;
    font-weight: 500;
    text-align: center;
    color: #333333;
    margin-top: 22px;
    margin-bottom: 24px;
    padding: 0px;
}

.sectionHeading {
    font-size: 24px;
    font-weight: 700;
    text-align: left;
    color: #333333;
    margin-top: 24px;
    padding: 0px;
}

.noteHeading {
    font-size: 18px;
    font-weight: 700;
    text-align: left;
    color: #333333;
    margin-top: 20px;
    padding: 0px;
}

.noteText {
    font-size: 18px;
    font-weight: 500;
    text-align: left;
    color: #333333;
    margin: 2px 0px 0px;
    padding: 0px;
}

.highlight_blue {
    color: rgb(178, 205, 251);
}

.highlight_orange {
    color: #ffd7ae;
}

.highlight_pink {
    color: rgb(255, 191, 206);
}

.highlight_yellow {
    color: rgb(247, 206, 0);
}

.notebookGraphic {
    margin-top: 10px;
    text-align: left;
}

.notebookGraphic img {
    -o-box-shadow:      0px 0px 5px #888;
    -icab-box-shadow:   0px 0px 5px #888;
    -khtml-box-shadow:  0px 0px 5px #888;
    -moz-box-shadow:    0px 0px 5px #888;
    -webkit-box-shadow: 0px 0px 5px #888;
    box-shadow:         0px 0px 5px #888; 
    max-width: 100%;
    height: auto;
}

hr {
    border: 0px none;
    height: 1px;
    background: none repeat scroll 0% 0% rgb(221, 221, 221);
}

		</style>
		<script type="text/javascript">
		    
		</script>
		<title></title>
	</head>
    <body>
        <div class="bodyContainer">
            <div class="notebookFor">
Notebook for
</div>
<div class="bookTitle">
Numsense! Data Science for the Layman: No Math Added
</div>
<div class="authors">
Ng, Annalyn
</div>
<div class="citation">
Citation (APA): Ng, A. (2017). <i>Numsense! Data Science for the Layman: No Math Added</i> [Kindle Android version]. Retrieved from Amazon.com
</div>
<hr />

            <div class="sectionHeading">
9. Decision Tree
</div>
<div class="noteHeading">
Highlight (<span class="highlight_yellow">yellow</span>) - 9.1 Predicting Survival in a Disaster >  Page 77
</div>
<div class="noteText">
A decision tree would predict chance of survival through a series of binary questions (see Figure 1), such that each question has only two possible responses (e.g. ‘yes’ or ‘no’). You would start at the top question, also known as the root node, and move through the tree branches as guided by your responses, until you finally reach a leaf node that indicates your predicted chance of survival.
</div>
<div class="sectionHeading">
10. Random Forests
</div>
<div class="noteHeading">
Highlight (<span class="highlight_yellow">yellow</span>) - 10.6 Summary >  Page 90
</div>
<div class="noteText">
A random forest often yields better prediction accuracy than decision trees because it leverages two techniques: bootstrap aggregating and ensembling. Bootstrap aggregating involves generating a series of uncorrelated decision trees by randomly restricting variables during the splitting process, while ensembling involves combining the predictions of these trees. While results of a random forest are not interpretable, predictors can still be ranked according to their contributions to prediction accuracy.
</div>
<div class="sectionHeading">
12. A/B Testing and Multi-Armed Bandits
</div>
<div class="noteHeading">
Highlight (<span class="highlight_yellow">yellow</span>) - 12.3 Epsilon-Decreasing Strategy >  Page 105
</div>
<div class="noteText">
This approach leverages the epsilon-decreasing strategy. Epsilon refers to the proportion of time spent exploring an alternative, to ensure that it is indeed less effective.
</div>
<div class="sectionHeading">
Appendix
</div>
<div class="noteHeading">
Highlight (<span class="highlight_yellow">yellow</span>) - C. List of Tuning Parameters >  Page 113
</div>
<div class="noteText">
D.
</div>
<div class="noteHeading">
Highlight (<span class="highlight_blue">blue</span>) - D. More Evaluation Metrics >  Page 114
</div>
<div class="noteText">
Classification Metrics Area Under the Receiver Operating Characteristic (AUROC) Curve. Also known more generically as Area Under the Curve (AUC), this metric allows us to choose between maximizing the true positive rate or minimizing the false positive rate. True Positive Rate (TPR) refers to the proportion of all positive points that were correctly classified as positive: TPR = TP / (TP + FN) False Positive Rate (FPR) refers to the proportion of all negative points that were incorrectly classified as positive: FPR = FP / (FP + TN) In an extreme case, we could choose to fully maximize the true positive rate, where TPR is set to 1, by predicting all points to be positive. While this would eliminate false negatives, it would significantly increase the number of false positives. In other words, there is a trade-off between minimizing false positives and maximizing true positives. This trade-off could be visualized using a Receiver Operating Characteristic (ROC) curve, as shown in Figure 1. Figure 1. An ROC curve showing the trade-off between maximizing true positives and minimizing false positives. The performance of the model is measured using the area under the ROC curve, thus giving the metric its name. The more accurate the model, the closer the curve would be to the plot’s top-left edges. A perfect prediction model would generate a curve with an AUC of 1, equivalent to the entire plot area. In contrast, the performance of a model with random predictions would be represented by the diagonal dotted line, with an AUC of 0.5. In practice, we could identify the best prediction model as the one yielding the highest AUC, and its ROC curve could then be used to select an appropriate threshold for the TPR or FPR that we would be willing to tolerate. Now, while the ROC curve allows us to be selective about the type of error we wish to avoid, we could also penalize all wrong predictions in general using a logarithmic loss metric. Logarithmic Loss (Log Loss). Predictions for binary and categorical variables are generally expressed as a probability, such as the probability that a customer would buy fish. The closer this probability is to 100%, the more confident the model is that the customer would purchase fish. The log loss metric takes advantage of this measure of confidence to calibrate its penalties for wrong predictions—specifically, the more confident a model is of a wrong prediction, the heavier its penalty on the log loss metric. Figure 2. Log loss penalty increases as a model’s confidence in a wrong prediction increases. Figure 2 shows the drastic increase in penalty as confidence in a wrong prediction approaches the upper limit. For example, if our model predicts an 80% chance that a customer would buy fish, but this turns out to be wrong, we would be penalized 0.7 points. If our model had instead predicted a 99% chance that fish would be bought, our penalty would more than double to 2 points. Due to its ability to adjust penalties based on prediction confidence, the log loss metric is commonly used in cases where wrong predictions are particularly detrimental. Regression Metrics Mean Absolute Error (MAE). A simple way to evaluate a regression model is to penalize all errors equally, by taking the average gap between predicted and actual values across all data points. This metric is called the mean absolute error. Root Mean Squared Logarithmic Error (RMSLE). In Chapter 1.4, we introduced the root mean squared error metric, which amplifies the penalty for large errors. In addition to the magnitude of error, we could also account for the direction of error using the root mean squared logarithmic error (RMSLE) metric. The RMSLE could be used if we wish to avoid under-estimates more than over-estimates, such as when predicting demand for umbrellas on a rainy day. Under-estimation would result in unhappy customers and lost revenue, whereas over-estimation would lead only to extra inventory. Glossary A/B Testing. A strategy to compare the returns from two products, A and B. The process starts with an exploration phase, where both products are tested at the same rate. After which, the better product is identified and all resources are devoted to it to maximize returns in an exploitation phase. The degree of trade-off between exploration (to check for better alternatives) and exploitation (to increase potential rewards) is a central decision for the conduct of any A/B test. Activation Rule. A criterion that specifies the source and strength of input signals that a neuron has to receive before it is activated. Neuron activations are propagated through a neural network to generate predictions. Apriori Principle. A rule which states that if an itemset is infrequent, then any larger itemset containing it must also be infrequent. It is a technique used to reduce the number of configurations we need to examine in measuring frequency and associations of items. Association Rules. An unsupervised learning technique that discovers how data points are associated with each other, such as identifying items that are frequently bought together. There are three common measures of association: Support of {X} indicates how frequently item X appears Confidence of {X->Y} indicates how frequently item Y appears when item X is present Lift of {X->Y} indicates how frequently items X and Y appear together, while accounting for how frequently each would appear on its own Backpropagation. A process of sending feedback in a neural network on whether a prediction was accurate. If a prediction was wrong, the error would be sent across the neural pathway in a backward pass so that neurons along that path would re-calibrate their activation criteria in order to reduce the error. Best-Fit Line. A trend line that passes through or sits close to as many data points as possible. Black Box. A term used to describe a prediction model that is uninterpretable, in that it does not have a clear formula for deriving its predictions. Bootstrap Aggregating (Bagging). A technique to create thousands of uncorrelated decision trees, from which predictions are averaged to prevent overfitting. Each tree is generated from a random subset of the training data, using a random subset of predictor variables for selection at each tree branch. Classification. A class of supervised learning techniques where we predict binary or categorical values. Confusion Matrix. A metric to evaluate the accuracy of classification predictions. Apart from overall classification accuracy, the matrix shows rates of false positives and false negatives. Correlation. A metric to measure the linear association between two variables. Correlation coefficients range from -1 to 1, and provide two pieces of information: 1) strength of association, which is maximized at -1 or 1 and minimized at 0, as well as 2) direction of association, which is positive when the two variables move together in the same direction, and negative otherwise. Cross-Validation. A technique to maximize the availability of data for validation by dividing the dataset into several segments that are used to test the model repeatedly. In a single iteration, all but one of the segments are used to train a prediction model, which is then tested on the last segment. This process is repeated until each segment has been used as the test segment exactly once. The final estimate of the model’s prediction accuracy is taken as the average of that across all iterations. Decision Tree. A supervised learning technique that makes predictions by asking a sequence of binary questions to repeatedly partition data points to obtain homogeneous groups. While easy to understand and visualize, decision trees are prone to overfitting. Dimension Reduction. A process of decreasing the number of variables in the data, such as by combining highly correlated ones. Dropout. A technique to prevent overfitting a neural network model, where we randomly exclude a different subset of neurons during each training cycle, forcing different combinations of neurons to work together to uncover more features. Ensembling. A technique to combine multiple prediction models to improve accuracy. It works well because models that yield accurate predictions tend to reinforce each other, while wrong predictions cancel each other out. Epsilon-Decreasing Strategy. A reinforcement learning technique for allocating resources that intersperses two phases: 1) exploring for better alternatives, and 2) exploiting known returns. Epsilon is the proportion of time spent exploring alternatives, and is decreased as more information is gained on which is the best alternative. Feature Engineering. A process of generating new variables creatively, such as by recoding a single variable, or by combining multiple ones. Gradient Boosting. A supervised learning technique that generates multiple decision trees by selecting different combinations of binary questions to grow each tree branch. Binary questions are selected strategically (instead of randomly, as in random forests), such that prediction accuracy for each subsequent tree improves. Predictions from individual trees are then combined, with latter trees given a heavier weight, to generate final predictions. Gradient Descent. A technique to tune model parameters. It makes an initial estimate on a set of parameter values, before starting an iterative process of applying these estimates to every data point to get predictions, and then revising the estimates to reduce overall prediction error. k-Means Clustering. An unsupervised learning technique that groups similar data points together, where k is the number of groups to be identified. k-Nearest Neighbors. A supervised learning technique that classifies a data point by referring to classifications of other data points it is closest to, where k is the number of data points to reference. Kernel Trick. A technique to project data points onto a higher dimension, where data points can be separated by a straight boundary. These straight boundaries are simpler to compute, and are also easily translated into curved ones when projected back down onto a lower dimension. Louvain Method. An unsupervised learning technique that identifies clusters in a network, in a way that maximizes interactions within clusters and minimizes those between clusters. Multi-Arm Bandit Problem. A term used to refer to any problem on resource allocation, such as deciding which slot machine to place bets on. The term was inspired by the moniker for slot machines—one-arm bandits—as they appear to cheat players of money with each arm pull. Multicollinearity. A problem in regression analysis where inclusion of highly correlated predictors result in distorted interpretations of regression weights. Neural Network. A supervised learning technique that uses layers of neurons to transmit activations for learning and making predictions. While highly accurate, results are largely uninterpretable due to its complexity. Overfitting. A phenomenon where a prediction model is overly sensitive and mistakes random variations in data as persistent patterns. An overfitted model would yield highly accurate predictions for current data, but would be less generalizable to future data. PageRank. An algorithm that identifies dominant nodes in a network. It ranks nodes based on their number of links, as well as the strength and source of those links. Parameter Tuning. A process of adjusting an algorithm’s settings to improve the accuracy of the resulting model, much like tuning a radio for the right frequency channel. Principal Component Analysis. An unsupervised learning technique that reduces the number of variables we have to analyze by combining the most informative variables in our data into new variables called principal components. Random Forest. A supervised learning technique that generates multiple decision trees by selecting different combinations of binary questions at random to grow each tree branch. Predictions from individual trees are then aggregated to generate final predictions. Recursive Partitioning. A process of repeatedly splitting a data sample to obtain homogeneous groups, as used in decision trees. Regression Analysis. A supervised learning technique that finds the best-fit trend line that passes through or sits close to as many data points as possible. The trend line is derived from a weighted combination of predictors. Regularization. A technique to prevent overfitting a prediction model by introducing a penalty parameter that artificially inflates prediction error with any increase in the model’s complexity. This enables us to account for both complexity and accuracy in optimizing model parameters. Reinforcement Learning. A class of machine learning algorithms that is used when we want to make predictions based on patterns in our data, and to continuously improve those predictions as more results come in. Root Mean Squared Error. A metric to evaluate the accuracy of regression predictions. It is particularly useful in cases where we want to avoid large errors. As each individual error is squared, large errors are amplified, rendering the metric extremely sensitive to outliers. Scree Plot. A graph used to determine how many groups we wish to keep. Groups can range from data clusters to reduced dimensions. The optimal number of groups is usually determined by the location of a kink, which is a sharp bend in the scree plot. Beyond this point, allowing more groups might yield less generalizable results. Standardization. A process that shifts variables onto a uniform standard scale, analogous to expressing each variable in terms of its percentiles. Subsampling. A technique to prevent overfitting a neural network model, where we ‘smoothen’ out the input training data by taking averages. If we are performing this on images for instance, we could reduce image size or lower color contrast. Supervised Learning. A class of machine learning algorithms that is used to make predictions. These algorithms are supervised because we want them to base their predictions on pre-existing patterns in our data. Support Vector Machine. A supervised learning technique that classifies data points into two groups by drawing a boundary down the middle between the peripheral data points, also called support vectors, of both groups. It employs the kernel trick to efficiently derive curved boundaries. Test Dataset. A data sample that is used to assess the accuracy and generalizability of a prediction model. The test dataset is withheld initially while the model is generated from a training dataset. Training Dataset. A data sample that is used to discover potentially predictive relationships to generate a prediction model. The model is then assessed using a separate test dataset. Translational Invariance. A property of convolutional neural networks, where image features are recognized regardless of where they are positioned on the image. Underfitting. A phenomenon where a prediction model is too insensitive, and overlooks underlying patterns. An underfitted model is likely to neglect significant trends, which would cause it to give less accurate predictions for both current and future data. Unsupervised Learning. A class of machine learning algorithms that is used to find hidden patterns in our data. These algorithms are unsupervised because we do not know what patterns to look out for and thus leave them to be uncovered by the algorithms. Validation. An assessment of how accurate our model is in predicting new data. It involves splitting the current dataset into two parts: the first part serves as a training dataset to generate and tune our prediction model, while the second part acts as a proxy for new data and is used as a test dataset to assess our model’s accuracy. Variable. Information that describes your data points. Variables are also known as attributes, features, or dimensions. There are different types of variables: Binary. The simplest type of variable, with only two possible options (e.g. male vs. female). Categorical. A variable that is used to represent more than two options (e.g. ethnicity). Integer. A variable that is used to represent whole numbers (e.g. age). Continuous. The most detailed type of variable, representing numbers with decimal places (e.g. price).
</div>

        </div>
    </body>
</html>
